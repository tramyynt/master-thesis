{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"/home_remote\"\n",
    "HOME = \"/home/thi.tra.my.nguyen\"\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import zipfile\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Wiki pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('/home_remote/fastText/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get word embeddings for a document\n",
    "def get_document_embeddings(document, max_length=100):\n",
    "    # Tokenize the document and get the first max_length word vectors\n",
    "    tokens = document.split()[:max_length]\n",
    "    \n",
    "    # Apply zero-padding if the document is shorter than max_length\n",
    "    if len(tokens) < max_length:\n",
    "        padding_count = max_length - len(tokens)\n",
    "        tokens.extend(['<PAD>'] * padding_count)\n",
    "\n",
    "    # Get word embeddings for each token\n",
    "    embeddings = [ft.get_word_vector(token) for token in tokens]\n",
    "\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_df_path = os.path.join(HOME_DIR, \"positive_df.pkl\")\n",
    "negatives_df_path = os.path.join(HOME_DIR, \"negative_df.pkl\")\n",
    "\n",
    "positives = pd.read_pickle(positives_df_path)\n",
    "negatives = pd.read_pickle(negatives_df_path)\n",
    "\n",
    "positives['Label'] = 1\n",
    "negatives['Label'] = 0\n",
    "\n",
    "#concatenate the two dataframes\n",
    "df = pd.concat([positives, negatives], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = df.TrainSubjectId.unique()\n",
    "#split the subjects into train and test\n",
    "train_subject, test_subject = train_test_split(subject, test_size=0.2, random_state=42, shuffle=True)\n",
    "df_train = df[df.TrainSubjectId.isin(train_subject)]\n",
    "df_test = df[df.TrainSubjectId.isin(test_subject)]\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_test = df_test.sample(frac=1, random_state=42)\n",
    "y_train = df_train.Label\n",
    "y_test = df_test.Label\n",
    "X_train = df_train['Text']\n",
    "X_test = df_test['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CReLU activation function\n",
    "def crelu(x):\n",
    "    pos = K.relu(x)\n",
    "    neg = K.relu(-x)\n",
    "    return K.concatenate([pos, neg], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 21:08:25.140207: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-04 21:08:25.682408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:8d:00.0, compute capability: 3.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 99, 100)           60100     \n",
      "                                                                 \n",
      " activation (Activation)     (None, 99, 200)           0         \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 99, 200)           0         \n",
      "                                                                 \n",
      " max_pooling1d (MaxPooling1D  (None, 1, 200)           0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200)               40200     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200)               20100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 100)               10050     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 130,652\n",
      "Trainable params: 130,652\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Word embedding dimensionality\n",
    "word_vector_dimensions = 300\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer\n",
    "model.add(Conv1D(filters=100, kernel_size=2, input_shape=(100, 300)))\n",
    "model.add(Activation(crelu))\n",
    "model.add(Activation(lambda x: x * -1))  # Negated activation for CReLU\n",
    "\n",
    "# 1-Max Pooling Layer\n",
    "model.add(MaxPooling1D(pool_size=99))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 3 Fully Connected Layers\n",
    "model.add(Dense(100, activation=crelu))\n",
    "model.add(Dense(50, activation=crelu))\n",
    "\n",
    "# Final Layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert X_train and X_test to word embedding using get_document_embeddings function\n",
    "X_train = np.array([get_document_embeddings(document) for document in X_train])\n",
    "X_test = np.array([get_document_embeddings(document) for document in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 21:44:29.894843: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 28491240000 exceeds 10% of free system memory.\n",
      "2023-12-04 21:44:58.498608: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 26.53GiB (rounded to 28491240192)requested by op _EagerConst\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-12-04 21:44:58.498683: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2023-12-04 21:44:58.498721: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 19, Chunks in use: 19. 4.8KiB allocated for chunks. 4.8KiB in use in bin. 292B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498744: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 3, Chunks in use: 2. 1.8KiB allocated for chunks. 1.0KiB in use in bin. 800B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498766: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 3, Chunks in use: 3. 3.2KiB allocated for chunks. 3.2KiB in use in bin. 2.6KiB client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498789: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498812: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498831: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498850: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498869: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498901: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 3, Chunks in use: 2. 230.0KiB allocated for chunks. 155.2KiB in use in bin. 117.2KiB client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498926: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 3, Chunks in use: 2. 622.2KiB allocated for chunks. 390.8KiB in use in bin. 390.6KiB client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498946: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498965: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.498987: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.81MiB allocated for chunks. 1.81MiB in use in bin. 1.81MiB client-requested in use in bin.\n",
      "2023-12-04 21:44:58.499007: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.499026: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.499045: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.499064: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.499089: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.499108: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.499127: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.499148: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 1, Chunks in use: 0. 10.54GiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-12-04 21:44:58.499170: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 26.53GiB was 256.00MiB, Chunk State: \n",
      "2023-12-04 21:44:58.499202: I tensorflow/core/common_runtime/bfc_allocator.cc:1039]   Size: 10.54GiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 1.81MiB | Requested Size: 1.81MiB | in_use: 1 | bin_num: -1\n",
      "2023-12-04 21:44:58.499220: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 11319115776\n",
      "2023-12-04 21:44:58.499243: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0000 of size 256 next 1\n",
      "2023-12-04 21:44:58.499261: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0100 of size 1280 next 2\n",
      "2023-12-04 21:44:58.499277: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0600 of size 256 next 3\n",
      "2023-12-04 21:44:58.499293: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/thi.tra.my.nguyen/master_thesis/model_evaluation/embedding_model.ipynb Cell 12\u001b[0m line \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsupmic2/home/thi.tra.my.nguyen/master_thesis/model_evaluation/embedding_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bsupmic2/home/thi.tra.my.nguyen/master_thesis/model_evaluation/embedding_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsupmic2/home/thi.tra.my.nguyen/master_thesis/model_evaluation/embedding_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Make predictions on the test set\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsupmic2/home/thi.tra.my.nguyen/master_thesis/model_evaluation/embedding_model.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "203be0700 of size 256 next 4\n",
      "2023-12-04 21:44:58.499309: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0800 of size 256 next 5\n",
      "2023-12-04 21:44:58.499327: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0900 of size 512 next 6\n",
      "2023-12-04 21:44:58.499343: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0b00 of size 256 next 9\n",
      "2023-12-04 21:44:58.499362: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0c00 of size 256 next 10\n",
      "2023-12-04 21:44:58.499379: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0d00 of size 1024 next 11\n",
      "2023-12-04 21:44:58.499399: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1100 of size 256 next 12\n",
      "2023-12-04 21:44:58.499415: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1200 of size 256 next 14\n",
      "2023-12-04 21:44:58.499433: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1300 of size 512 next 15\n",
      "2023-12-04 21:44:58.499451: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1500 of size 256 next 16\n",
      "2023-12-04 21:44:58.499466: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1600 of size 256 next 19\n",
      "2023-12-04 21:44:58.499482: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1700 of size 256 next 20\n",
      "2023-12-04 21:44:58.499497: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1800 of size 256 next 21\n",
      "2023-12-04 21:44:58.499513: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1900 of size 256 next 23\n",
      "2023-12-04 21:44:58.499529: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1a00 of size 256 next 24\n",
      "2023-12-04 21:44:58.499544: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1b00 of size 256 next 25\n",
      "2023-12-04 21:44:58.499560: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1c00 of size 256 next 28\n",
      "2023-12-04 21:44:58.499575: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1d00 of size 256 next 29\n",
      "2023-12-04 21:44:58.499596: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1e00 of size 256 next 31\n",
      "2023-12-04 21:44:58.499612: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be1f00 of size 256 next 32\n",
      "2023-12-04 21:44:58.499628: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 4203be2000 of size 768 next 26\n",
      "2023-12-04 21:44:58.499644: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be2300 of size 1024 next 27\n",
      "2023-12-04 21:44:58.499660: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 4203be2700 of size 76544 next 22\n",
      "2023-12-04 21:44:58.499676: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203bf5200 of size 78848 next 17\n",
      "2023-12-04 21:44:58.499719: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203c08600 of size 80128 next 18\n",
      "2023-12-04 21:44:58.499736: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 4203c1bf00 of size 237056 next 7\n",
      "2023-12-04 21:44:58.499753: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203c55d00 of size 240128 next 8\n",
      "2023-12-04 21:44:58.499770: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203c90700 of size 160000 next 13\n",
      "2023-12-04 21:44:58.499788: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203cb7800 of size 1899520 next 30\n",
      "2023-12-04 21:44:58.499813: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 4203e87400 of size 11316333568 next 18446744073709551615\n",
      "2023-12-04 21:44:58.499829: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2023-12-04 21:44:58.499849: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 19 Chunks of size 256 totalling 4.8KiB\n",
      "2023-12-04 21:44:58.499868: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 512 totalling 1.0KiB\n",
      "2023-12-04 21:44:58.499888: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 1024 totalling 2.0KiB\n",
      "2023-12-04 21:44:58.499907: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-12-04 21:44:58.499927: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 78848 totalling 77.0KiB\n",
      "2023-12-04 21:44:58.499948: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 80128 totalling 78.2KiB\n",
      "2023-12-04 21:44:58.499969: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 160000 totalling 156.2KiB\n",
      "2023-12-04 21:44:58.499988: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 240128 totalling 234.5KiB\n",
      "2023-12-04 21:44:58.500007: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1899520 totalling 1.81MiB\n",
      "2023-12-04 21:44:58.500025: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 2.35MiB\n",
      "2023-12-04 21:44:58.500043: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 11319115776 memory_limit_: 11319115776 available bytes: 0 curr_region_allocation_bytes_: 22638231552\n",
      "2023-12-04 21:44:58.500068: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                     11319115776\n",
      "InUse:                         2467840\n",
      "MaxInUse:                      2467840\n",
      "NumAllocs:                          44\n",
      "MaxAllocSize:                  1899520\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-12-04 21:44:58.500096: W tensorflow/core/common_runtime/bfc_allocator.cc:474] *___________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Get the 98th percentile of the predictions\n",
    "percentile_98 = np.percentile(y_pred, 98)\n",
    "\n",
    "print(\"98th Percentile of Predictions:\", percentile_98)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 14367927769888350324\n",
      "xla_global_id: -1\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 11319115776\n",
      "locality {\n",
      "  bus_id: 2\n",
      "  numa_node: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 323540787456691409\n",
      "physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:8d:00.0, compute capability: 3.7\"\n",
      "xla_global_id: 416903419\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 21:47:40.188720: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 10794 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:8d:00.0, compute capability: 3.7\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
