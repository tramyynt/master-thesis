{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"/home_remote\"\n",
    "HOME = \"/home/thi.tra.my.nguyen\"\n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import zipfile\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dense, MaxPooling1D, Flatten, Dropout, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import fasttext\n",
    "import fasttext.util\n",
    "\n",
    "\n",
    "import ast\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Wiki pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('/home_remote/fastText/cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to get word embeddings for a document\n",
    "def get_document_embeddings(document, max_length=100):\n",
    "    # Tokenize the document and get the first max_length word vectors\n",
    "    tokens = document.split()[:max_length]\n",
    "    \n",
    "    # Apply zero-padding if the document is shorter than max_length\n",
    "    if len(tokens) < max_length:\n",
    "        padding_count = max_length - len(tokens)\n",
    "        tokens.extend(['<PAD>'] * padding_count)\n",
    "\n",
    "    # Get word embeddings for each token\n",
    "    embeddings = [ft.get_word_vector(token) for token in tokens]\n",
    "\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_df_path = os.path.join(HOME_DIR, \"positive_df.pkl\")\n",
    "negatives_df_path = os.path.join(HOME_DIR, \"negative_df.pkl\")\n",
    "\n",
    "positives = pd.read_pickle(positives_df_path)\n",
    "negatives = pd.read_pickle(negatives_df_path)\n",
    "\n",
    "positives['Label'] = 1\n",
    "negatives['Label'] = 0\n",
    "\n",
    "#concatenate the two dataframes\n",
    "df = pd.concat([positives, negatives], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = df.TrainSubjectId.unique()\n",
    "#split the subjects into train and test\n",
    "train_subject, test_subject = train_test_split(subject, test_size=0.2, random_state=42, shuffle=True)\n",
    "df_train = df[df.TrainSubjectId.isin(train_subject)]\n",
    "df_test = df[df.TrainSubjectId.isin(test_subject)]\n",
    "df_train = df_train.sample(frac=1, random_state=42)\n",
    "df_test = df_test.sample(frac=1, random_state=42)\n",
    "y_train = df_train.Label\n",
    "y_test = df_test.Label\n",
    "X_train = df_train['Text']\n",
    "X_test = df_test['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CReLU activation function\n",
    "def crelu(x):\n",
    "    pos = K.relu(x)\n",
    "    neg = K.relu(-x)\n",
    "    return K.concatenate([pos, neg], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "# Word embedding dimensionality\n",
    "word_vector_dimensions = 300\n",
    "\n",
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "# Convolutional Layer\n",
    "model.add(Conv1D(filters=100, kernel_size=2, input_shape=(100, 300)))\n",
    "model.add(Activation(crelu))\n",
    "model.add(Activation(lambda x: x * -1))  # Negated activation for CReLU\n",
    "\n",
    "# 1-Max Pooling Layer\n",
    "model.add(MaxPooling1D(pool_size=99))\n",
    "\n",
    "# Fully Connected Layer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(200))\n",
    "\n",
    "# Dropout Layer\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# 3 Fully Connected Layers\n",
    "model.add(Dense(100, activation=crelu))\n",
    "model.add(Dense(50, activation=crelu))\n",
    "\n",
    "# Final Layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['f1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Get the 98th percentile of the predictions\n",
    "percentile_98 = np.percentile(y_pred, 98)\n",
    "\n",
    "print(\"98th Percentile of Predictions:\", percentile_98)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
