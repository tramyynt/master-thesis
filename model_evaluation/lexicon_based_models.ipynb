{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = \"/home_remote\"\n",
    "HOME = \"/home/thi.tra.my.nguyen\"\n",
    "\n",
    "from liwc import Liwc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk import word_tokenize, ngrams\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pickle\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#import logisitic_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives_df_path = os.path.join(HOME_DIR, \"positive_df.pkl\")\n",
    "negatives_df_path = os.path.join(HOME_DIR, \"negative_df.pkl\")\n",
    "\n",
    "positives = pd.read_pickle(positives_df_path)\n",
    "negatives = pd.read_pickle(negatives_df_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_liwc_input(df, label):\n",
    "  \"\"\"\n",
    "  params: df - The positive/negative dataframe loaded from pickle\n",
    "    The df is expected to has these columns \"Title\", \"Date\", \"Text\", \"SubjectId\"\n",
    "  params: label - The label need to be assigned to result dataframe\n",
    "\n",
    "  returns: A dataframe contains \"SubjectId\", \"AverageLength\", \"Text\", \"NumOfWritings\", \"Title\"\n",
    "  \"\"\"\n",
    "  subject_id_list = df.loc[:, \"TrainSubjectId\"].unique()\n",
    "  df[\"Token\"] = df[\"Text\"].apply(lambda x: word_tokenize(x))\n",
    "\n",
    "  df['text'] = df['Text']+ df['Title']\n",
    "\n",
    "  grouped_by_subject_id = df.groupby('TrainSubjectId')\n",
    "\n",
    "  # calculate average token length for each user\n",
    "  average_length_df = grouped_by_subject_id['Token'].apply(lambda token_series: sum(len(token) for token in token_series) / len(token_series)).reset_index()\n",
    "  average_length_df.rename(columns={'Token': 'AverageLength'}, inplace=True)\n",
    "  #print(average_length_df.head())\n",
    "\n",
    "  # join all writings of single user into single corpus\n",
    "  joined_text_df = grouped_by_subject_id['text'].apply(' '.join).reset_index()\n",
    "\n",
    "  # calculate number of writings for each user\n",
    "  number_of_writings_df = grouped_by_subject_id['Text'].apply(lambda x: len(x)).reset_index()\n",
    "  number_of_writings_df.rename(columns={'Text': 'NumOfWritings'}, inplace=True)\n",
    "\n",
    "  result_df = average_length_df.merge(joined_text_df, on=\"TrainSubjectId\")\n",
    "  result_df = result_df.merge(number_of_writings_df, on=\"TrainSubjectId\")\n",
    "  result_df[\"Label\"] = label\n",
    "\n",
    "  return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_positives = construct_liwc_input(positives, 1)\n",
    "input_negatives = construct_liwc_input(negatives, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "liwc_input = pd.concat([input_positives, input_negatives])\n",
    "liwc_input = liwc_input.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input = liwc_input[['TrainSubjectId', 'Label', 'text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hand-crafted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting textstat\n",
      "  Downloading textstat-0.7.3-py3-none-any.whl (105 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pyphen (from textstat)\n",
      "  Downloading pyphen-0.14.0-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyphen, textstat\n",
      "Successfully installed pyphen-0.14.0 textstat-0.7.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textstat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives['LWF'] = positives['Text'].apply(lambda x: textstat.linsear_write_formula(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Date</th>\n",
       "      <th>Text</th>\n",
       "      <th>Info</th>\n",
       "      <th>TrainSubjectId</th>\n",
       "      <th>Token</th>\n",
       "      <th>text</th>\n",
       "      <th>LWF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2015-06-13 22:06:19</td>\n",
       "      <td>I'm pretty sure the definition is \"It's not s...</td>\n",
       "      <td>reddit post</td>\n",
       "      <td>train_subject96</td>\n",
       "      <td>[I, 'm, pretty, sure, the, definition, is, ``,...</td>\n",
       "      <td>I'm pretty sure the definition is \"It's not s...</td>\n",
       "      <td>49.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2015-02-23 05:35:18</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>reddit post</td>\n",
       "      <td>train_subject405</td>\n",
       "      <td>[Thank, you, very, much, .]</td>\n",
       "      <td>Thank you very much.</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2015-02-23 05:00:31</td>\n",
       "      <td>Haha.</td>\n",
       "      <td>reddit post</td>\n",
       "      <td>train_subject405</td>\n",
       "      <td>[Haha, .]</td>\n",
       "      <td>Haha.</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003 Crown Vic</td>\n",
       "      <td>2015-02-23 00:32:01</td>\n",
       "      <td>2FAFP71W23X220401</td>\n",
       "      <td>reddit post</td>\n",
       "      <td>train_subject405</td>\n",
       "      <td>[2FAFP71W23X220401]</td>\n",
       "      <td>2FAFP71W23X220401  2003 Crown Vic</td>\n",
       "      <td>-0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2015-01-30 04:22:56</td>\n",
       "      <td>I already got my refund! it was approved than...</td>\n",
       "      <td>reddit post</td>\n",
       "      <td>train_subject405</td>\n",
       "      <td>[I, already, got, my, refund, !, it, was, appr...</td>\n",
       "      <td>I already got my refund! it was approved than...</td>\n",
       "      <td>2.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2015-07-18 23:27:05</td>\n",
       "      <td>Why thank you and greatly appreciate the info...</td>\n",
       "      <td>reddit post</td>\n",
       "      <td>train_subject8741</td>\n",
       "      <td>[Why, thank, you, and, greatly, appreciate, th...</td>\n",
       "      <td>Why thank you and greatly appreciate the info...</td>\n",
       "      <td>3.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>2014-11-14 19:09:23</td>\n",
       "      <td>Horrible caption.</td>\n",
       "      <td>reddit post</td>\n",
       "      <td>train_subject7042</td>\n",
       "      <td>[Horrible, caption, .]</td>\n",
       "      <td>Horrible caption.</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td>2014-11-06 03:45:20</td>\n",
       "      <td>That's actually terrifying</td>\n",
       "      <td>reddit post</td>\n",
       "      <td>train_subject7042</td>\n",
       "      <td>[That, 's, actually, terrifying]</td>\n",
       "      <td>That's actually terrifying</td>\n",
       "      <td>2.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td>2014-11-06 01:06:07</td>\n",
       "      <td>Where can you purchase these?</td>\n",
       "      <td>reddit post</td>\n",
       "      <td>train_subject7042</td>\n",
       "      <td>[Where, can, you, purchase, these, ?]</td>\n",
       "      <td>Where can you purchase these?</td>\n",
       "      <td>1.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td>2014-06-25 03:42:15</td>\n",
       "      <td>I'm just Ass.Treasure</td>\n",
       "      <td>reddit post</td>\n",
       "      <td>train_subject7042</td>\n",
       "      <td>[I, 'm, just, Ass.Treasure]</td>\n",
       "      <td>I'm just Ass.Treasure</td>\n",
       "      <td>1.500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30955 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Title                   Date  \\\n",
       "0                      2015-06-13 22:06:19    \n",
       "0                      2015-02-23 05:35:18    \n",
       "1                      2015-02-23 05:00:31    \n",
       "2    2003 Crown Vic    2015-02-23 00:32:01    \n",
       "3                      2015-01-30 04:22:56    \n",
       "..               ...                    ...   \n",
       "0                      2015-07-18 23:27:05    \n",
       "0                      2014-11-14 19:09:23    \n",
       "1                      2014-11-06 03:45:20    \n",
       "2                      2014-11-06 01:06:07    \n",
       "3                      2014-06-25 03:42:15    \n",
       "\n",
       "                                                 Text           Info  \\\n",
       "0    I'm pretty sure the definition is \"It's not s...   reddit post    \n",
       "0                               Thank you very much.    reddit post    \n",
       "1                                              Haha.    reddit post    \n",
       "2                                  2FAFP71W23X220401    reddit post    \n",
       "3    I already got my refund! it was approved than...   reddit post    \n",
       "..                                                ...            ...   \n",
       "0    Why thank you and greatly appreciate the info...   reddit post    \n",
       "0                                  Horrible caption.    reddit post    \n",
       "1                        That's actually terrifying     reddit post    \n",
       "2                      Where can you purchase these?    reddit post    \n",
       "3                              I'm just Ass.Treasure    reddit post    \n",
       "\n",
       "       TrainSubjectId                                              Token  \\\n",
       "0     train_subject96  [I, 'm, pretty, sure, the, definition, is, ``,...   \n",
       "0    train_subject405                        [Thank, you, very, much, .]   \n",
       "1    train_subject405                                          [Haha, .]   \n",
       "2    train_subject405                                [2FAFP71W23X220401]   \n",
       "3    train_subject405  [I, already, got, my, refund, !, it, was, appr...   \n",
       "..                ...                                                ...   \n",
       "0   train_subject8741  [Why, thank, you, and, greatly, appreciate, th...   \n",
       "0   train_subject7042                             [Horrible, caption, .]   \n",
       "1   train_subject7042                   [That, 's, actually, terrifying]   \n",
       "2   train_subject7042              [Where, can, you, purchase, these, ?]   \n",
       "3   train_subject7042                        [I, 'm, just, Ass.Treasure]   \n",
       "\n",
       "                                                 text     LWF  \n",
       "0    I'm pretty sure the definition is \"It's not s...  49.000  \n",
       "0                            Thank you very much.       1.000  \n",
       "1                                           Haha.      -0.500  \n",
       "2                  2FAFP71W23X220401  2003 Crown Vic   -0.500  \n",
       "3    I already got my refund! it was approved than...   2.250  \n",
       "..                                                ...     ...  \n",
       "0    Why thank you and greatly appreciate the info...   3.875  \n",
       "0                               Horrible caption.       1.000  \n",
       "1                     That's actually terrifying        2.500  \n",
       "2                   Where can you purchase these?       1.500  \n",
       "3                           I'm just Ass.Treasure       1.500  \n",
       "\n",
       "[30955 rows x 8 columns]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LIWC dictionary\n",
    "liwc = Liwc(os.path.join(HOME_DIR, \"master_thesis/LIWC2007_English100131.dic\"))\n",
    "input = [liwc.parse(word_tokenize(text)) for text in data_input['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load LIWC-alike dictionary\n",
    "%run /home_remote/master_thesis/model_evaluation/liwc_alike.py\n",
    "liwc_alike_output = [main(text, result) for text in data_input['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract top 15 features based on percentage. \n",
    "def get_features_top15(df, output):\n",
    "    #df['vector'] = output\n",
    "    vector_df = pd.DataFrame(output, index=df.index)\n",
    "    vector_df_norm = vector_df.div(vector_df.sum(axis=1), axis=0)\n",
    "    vector_df_norm['Label'] = df['Label']\n",
    "    vector_df_norm['TrainSubjectId'] = df['TrainSubjectId']\n",
    "    vector_df_norm = vector_df_norm.fillna(0)\n",
    "    corr = vector_df_norm.corr()\n",
    "    corr_label = corr['Label'].sort_values(ascending=False)\n",
    "    relevant_features = corr_label[1:40]\n",
    "    relevant_features_name = relevant_features.index.values\n",
    "    X = vector_df_norm[relevant_features_name]\n",
    "    y = vector_df_norm['Label']\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_liwc_alike_15, y_liwc_alike_15 = get_features_top15(data_input, liwc_alike_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using chi2 to extract top 15 features\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "def get_features_chi2(df, output):\n",
    "    vector_df = pd.DataFrame(output, index=df.index)\n",
    "    vector_df_norm = vector_df.div(vector_df.sum(axis=1), axis=0)\n",
    "    vector_df_norm['Label'] = df['Label']\n",
    "    vector_df_norm['TrainSubjectId'] = df['TrainSubjectId']\n",
    "    vector_df_norm = vector_df_norm.fillna(0)\n",
    "    X = vector_df_norm.drop(['Label', 'TrainSubjectId'], axis=1)\n",
    "    y = vector_df_norm['Label']\n",
    "    X_new = SelectKBest(chi2, k=4).fit_transform(X, y)\n",
    "    return X_new, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extraction using mutual information\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "def get_features_mutual_info(df, output):\n",
    "    vector_df = pd.DataFrame(output, index=df.index)\n",
    "    vector_df_norm = vector_df.div(vector_df.sum(axis=1), axis=0)\n",
    "    vector_df_norm['Label'] = df['Label']\n",
    "    vector_df_norm['TrainSubjectId'] = df['TrainSubjectId']\n",
    "    vector_df_norm = vector_df_norm.fillna(0)\n",
    "    X = vector_df_norm.drop(['Label', 'TrainSubjectId'], axis=1)\n",
    "    y = vector_df_norm['Label']\n",
    "    X_new = SelectKBest(mutual_info_classif, k=15).fit_transform(X, y)\n",
    "    return X_new, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alike_chi_15, y_alike_chi_15 = get_features_chi2(data_input, liwc_alike_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_alike_mutual_15, y_alike_mutual_15 = get_features_mutual_info(data_input, liwc_alike_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(X, y):\n",
    "\n",
    "    w = [1, 2**1, 2**2, 2**3, 2**4, 2**5, 2**6,2**7, 2**8]\n",
    "    weight = [{0: 1/(1+x),  1: x/(1+x)} for x in w]\n",
    "    C = [2**-6, 2**-5, 2**-4, 2**-3, 2**-2, 2**-1, 1, 2**1, 2**2, 2**3, 2**4, 2**5, 2**6]\n",
    "    # define grid search\n",
    "    hyperparam_grid = {\"class_weight\": weight\n",
    "                    ,\"C\": C\n",
    "                    ,\"fit_intercept\": [True, False]  }\n",
    "    # define evaluation procedure\n",
    "    cv = KFold(n_splits=5, shuffle=True, random_state=13)\n",
    "    # define grid search\n",
    "    model_test = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "    grid = GridSearchCV(estimator=model_test, param_grid=hyperparam_grid, cv=cv, scoring='f1')\n",
    "    grid_result = grid.fit(X, y)\n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "\n",
    "    #build a model with the best parameters, fix class_weight = (0.2, 0.8)\n",
    "\n",
    "    model = LogisticRegression(**grid_result.best_params_)\n",
    "    model.fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.DataFrame(liwc_alike_output, index=data_input.index)\n",
    "b = a.div(a.sum(axis=1), axis=0)\n",
    "b = b.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save pca model\n",
    "pca = PCA(n_components=15)\n",
    "pca.fit(b)\n",
    "c = pca.transform(b)\n",
    "#joblib.dump(pca, os.path.join(HOME_DIR,'pca.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.610030 using {'C': 64, 'class_weight': {0: 0.2, 1: 0.8}, 'fit_intercept': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.86      0.89       403\n",
      "           1       0.48      0.65      0.55        83\n",
      "\n",
      "    accuracy                           0.82       486\n",
      "   macro avg       0.70      0.75      0.72       486\n",
      "weighted avg       0.85      0.82      0.83       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_pca = logistic_regression(c, data_input['Label'])\n",
    "y_pred_pca = model_pca.predict(c)\n",
    "print(classification_report(data_input['Label'], y_pred_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home_remote/model_pca_liwc_alike.pkl']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(model_pca, os.path.join(HOME_DIR,'model_pca_liwc_alike.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test with LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.621761 using {'C': 64, 'class_weight': {0: 0.3333333333333333, 1: 0.6666666666666666}, 'fit_intercept': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91       403\n",
      "           1       0.65      0.13      0.22        83\n",
      "\n",
      "    accuracy                           0.84       486\n",
      "   macro avg       0.75      0.56      0.57       486\n",
      "weighted avg       0.81      0.84      0.79       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = logistic_regression(X_liwc_alike_15, y_liwc_alike_15)\n",
    "y_pred_15 = model.predict(X_liwc_alike_15)\n",
    "print(classification_report(y_liwc_alike_15, y_pred_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.585963 using {'C': 64, 'class_weight': {0: 0.2, 1: 0.8}, 'fit_intercept': True}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.89       380\n",
      "           1       0.60      0.47      0.53       106\n",
      "\n",
      "    accuracy                           0.82       486\n",
      "   macro avg       0.73      0.69      0.71       486\n",
      "weighted avg       0.80      0.82      0.81       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test with X_alike_chi_15\n",
    "model_chi = logistic_regression(X_alike_chi_15, y_alike_chi_15)\n",
    "y_pred_15_chi = model_chi.predict(X_alike_chi_15)\n",
    "print(classification_report(y_pred_15_chi, y_alike_chi_15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.605273 using {'C': 16, 'class_weight': {0: 0.2, 1: 0.8}, 'fit_intercept': False}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91       482\n",
      "           1       0.04      0.75      0.07         4\n",
      "\n",
      "    accuracy                           0.83       486\n",
      "   macro avg       0.52      0.79      0.49       486\n",
      "weighted avg       0.99      0.83      0.90       486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#test with X_alike_mutual_15\n",
    "model_mutual = logistic_regression(X_alike_mutual_15, y_alike_mutual_15)\n",
    "y_pred_15_mutual = model_mutual.predict(X_alike_mutual_15)\n",
    "print(classification_report(y_pred_15_mutual, y_alike_mutual_15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 165172\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# Example text data (replace this with your actual text data)\n",
    "texts = data_input['text'].tolist()\n",
    "# Create a tokenizer and fit it on your text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(texts)\n",
    "\n",
    "# Get the vocabulary size\n",
    "vocabulary_size = len(tokenizer.word_index) + 1  # Add 1 for the special padding token if used\n",
    "\n",
    "print(\"Vocabulary Size:\", vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(c, data_input['Label'], test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-13 23:44:56.661048: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 7.5KiB (rounded to 7680)requested by op RandomUniform\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2023-11-13 23:44:56.661127: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2023-11-13 23:44:56.661156: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 4, Chunks in use: 3. 1.0KiB allocated for chunks. 768B in use in bin. 16B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661178: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661199: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661219: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661238: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661257: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661276: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661298: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661317: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661336: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661355: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661373: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661392: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661410: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661429: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661448: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661466: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661485: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661511: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 2, Chunks in use: 2. 165.62MiB allocated for chunks. 165.62MiB in use in bin. 161.30MiB client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661530: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661554: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2023-11-13 23:44:56.661575: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 7.5KiB was 4.0KiB, Chunk State: \n",
      "2023-11-13 23:44:56.661591: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 173670400\n",
      "2023-11-13 23:44:56.661613: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0000 of size 256 next 1\n",
      "2023-11-13 23:44:56.661630: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0100 of size 1280 next 2\n",
      "2023-11-13 23:44:56.661647: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0600 of size 256 next 3\n",
      "2023-11-13 23:44:56.661663: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0700 of size 256 next 4\n",
      "2023-11-13 23:44:56.661679: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4203be0800 of size 84568064 next 5\n",
      "2023-11-13 23:44:56.661695: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 4208c87000 of size 256 next 6\n",
      "2023-11-13 23:44:56.661712: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 4208c87100 of size 89100032 next 18446744073709551615\n",
      "2023-11-13 23:44:56.661727: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2023-11-13 23:44:56.661746: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 3 Chunks of size 256 totalling 768B\n",
      "2023-11-13 23:44:56.661764: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2023-11-13 23:44:56.661783: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 84568064 totalling 80.65MiB\n",
      "2023-11-13 23:44:56.661802: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 89100032 totalling 84.97MiB\n",
      "2023-11-13 23:44:56.661820: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 165.62MiB\n",
      "2023-11-13 23:44:56.661836: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 173670400 memory_limit_: 173670400 available bytes: 0 curr_region_allocation_bytes_: 347340800\n",
      "2023-11-13 23:44:56.661860: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                       173670400\n",
      "InUse:                       173670144\n",
      "MaxInUse:                    173670400\n",
      "NumAllocs:                           7\n",
      "MaxAllocSize:                 89100032\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2023-11-13 23:44:56.661880: W tensorflow/core/common_runtime/bfc_allocator.cc:474] **************************************************************************************************xx\n",
      "2023-11-13 23:44:56.661942: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at random_op.cc:74 : RESOURCE_EXHAUSTED: OOM when allocating tensor with shape[15,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[15,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/thi.tra.my.nguyen/master_thesis/model_evaluation/lexicon_based_models.ipynb Cell 24\u001b[0m line \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bsupmic2/home/thi.tra.my.nguyen/master_thesis/model_evaluation/lexicon_based_models.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m model2 \u001b[39m=\u001b[39m Sequential()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsupmic2/home/thi.tra.my.nguyen/master_thesis/model_evaluation/lexicon_based_models.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# Embedding layer\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bsupmic2/home/thi.tra.my.nguyen/master_thesis/model_evaluation/lexicon_based_models.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m model2\u001b[39m.\u001b[39;49madd(Embedding(input_dim \u001b[39m=\u001b[39;49m \u001b[39m15\u001b[39;49m , output_dim \u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsupmic2/home/thi.tra.my.nguyen/master_thesis/model_evaluation/lexicon_based_models.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m# LSTM layer with ReLU activation and dropout\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bsupmic2/home/thi.tra.my.nguyen/master_thesis/model_evaluation/lexicon_based_models.ipynb#X44sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m model2\u001b[39m.\u001b[39madd(LSTM(\u001b[39m128\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m, dropout\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, recurrent_dropout\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/tracking/base.py:629\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 629\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    630\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/backend.py:1920\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1917\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generator:\n\u001b[1;32m   1918\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generator\u001b[39m.\u001b[39muniform(\n\u001b[1;32m   1919\u001b[0m       shape\u001b[39m=\u001b[39mshape, minval\u001b[39m=\u001b[39mminval, maxval\u001b[39m=\u001b[39mmaxval, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m-> 1920\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49muniform(\n\u001b[1;32m   1921\u001b[0m     shape\u001b[39m=\u001b[39;49mshape, minval\u001b[39m=\u001b[39;49mminval, maxval\u001b[39m=\u001b[39;49mmaxval, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   1922\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_legacy_seed())\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[15,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "#lstm \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "# Define the model\n",
    "model2 = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model2.add(Embedding(input_dim = 15 , output_dim =128))\n",
    "\n",
    "# LSTM layer with ReLU activation and dropout\n",
    "model2.add(LSTM(128, activation='relu', dropout=0.3, recurrent_dropout=0.3))\n",
    "\n",
    "# Fully connected layer with ReLU activation\n",
    "model2.add(Dense(128, activation='relu', kernel_regularizer='l2', bias_regularizer='l2'))\n",
    "\n",
    "# Dropout layer\n",
    "model2.add(Dropout(0.3))\n",
    "\n",
    "# Output layer with softmax activation for binary classification\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=1e-4), metrics=['accuracy'])\n",
    "\n",
    "# Learning rate decay scheduler\n",
    "def lr_scheduler(epoch, lr):\n",
    "    return lr * np.exp(-1e-5 * epoch)\n",
    "\n",
    "lr_callback = LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Train the model\n",
    "model2.fit(X_train, y_train, epochs=130, batch_size=100, callbacks=[lr_callback], class_weight={0: 0.2, 1: 0.8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
